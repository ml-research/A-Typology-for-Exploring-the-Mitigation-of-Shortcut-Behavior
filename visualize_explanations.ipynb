{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize Explanations\n",
    "\n",
    "This notebook showcases the following expainer methods on pretrained models (DecoyMNIST MLP/CNN. The XIL losses utilize them to generate the models explanation. These model explanations are compared against the user feedback masks. Keep in mind that we currently do not use theses explanatio methods to generate the user feedback masks, as we are using predefined ground-truth masks in evaluation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using cuda device]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from learner.models import dnns\n",
    "from learner.learner import Learner\n",
    "from data_store.datasets import decoy_mnist, decoy_mnist_CE_augmented, isic_2019\n",
    "from xil_methods.xil_loss import RRRGradCamLoss, RRRLoss, CDEPLoss, HINTLoss, RBRLoss\n",
    "import util\n",
    "import explainer\n",
    "\n",
    "LR = 0.001\n",
    "SEED = [1, 10, 100, 1000, 10000]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[Using {DEVICE} device]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load pretrained model CNN no XIL \n",
    "The model was trained on DecoyMNIST with CrossEntropyLoss. The CNN has two conv layers and thre fc on top of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from existing file!\n"
     ]
    }
   ],
   "source": [
    "model = dnns.SimpleConvNet().to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "n = 0  # defines which XIL method to use/ visualize\n",
    "util.seed_all(SEED[n])\n",
    "reg = [None, 10, 10, 1000000, 2000000, 10000 , None]\n",
    "methods = ['CEL', 'RRR', 'RRRGradCAM', 'RBR', 'CDEP', 'HINT', 'CE']\n",
    "methods = ['Vanilla']\n",
    "IMAGE_INDICES = [34] # [i for i in range(20,28)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for j,data in enumerate(train_loader):\n",
    "    cur_save_name = 'output_images/noXIL_MNIST.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name ,cmap='gray', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == 0:\n",
    "        break\n",
    "               \n",
    "i = 0\n",
    "pretrained_modelname = f'DecoyMnist-CNN-{methods[i]}--reg={reg[i]}--seed={SEED[n]}--run={n}'\n",
    "learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "explainer.explain_with_ig_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_MNIST_{methods[i]}', next_to_each_other=True)\n",
    "explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_MNIST_{methods[i]}', flags=False, next_to_each_other=True)\n",
    "explainer.explain_with_lime_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_MNIST_{methods[i]}', gray_images=True, next_to_each_other=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using Seed= 1]\n",
      "Model DecoyFMnist-CNN-Vanilla--reg=None--seed=1--run=0 loaded! Was trained on CrossEntropyLoss() for 0 epochs!\n",
      "explanation image with name IG_FMNIST_Vanilla-34 saved!\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = decoy_mnist(fmnist=True, device=DEVICE, batch_size=256)\n",
    "for j,data in enumerate(train_loader):\n",
    "    cur_save_name = 'output_images/noXIL_FMNIST.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name ,cmap='gray', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == 0:\n",
    "        break\n",
    "               \n",
    "i = 0\n",
    "pretrained_modelname = f'DecoyFMnist-CNN-{methods[i]}--reg={reg[i]}--seed={SEED[n]}--run={n}'\n",
    "learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "explainer.explain_with_ig_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_FMNIST_{methods[i]}', next_to_each_other=True)\n",
    "explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_FMNIST_{methods[i]}', flags=False, next_to_each_other=True)\n",
    "explainer.explain_with_lime_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_FMNIST_{methods[i]}', gray_images=True, next_to_each_other=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ISIC19 Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Dataset----------\n",
      "  Read in data from .h5 files...\n",
      "  --> Read in finished: Took 93 sec!\n",
      "  Building datasets...\n",
      "  Sizes of datasets:\n",
      "  TRAIN: 17829, TEST: 2394, TEST_NO_PATCHES: 2556\n",
      "  TRAIN class dist: Counter({0: 15768, 1: 2061})\n",
      "  TRAIN patch dist: Counter({0: 10521, 1: 7308})\n",
      "  TEST class dist: Counter({0: 1902, 1: 492})\n",
      "  TEST_NO_PATCHES class dist: Counter({0: 2064, 1: 492})\n",
      "  Loss weights: tensor([0.1146, 0.8854])\n",
      "  --> Build finished: Took 3 sec!\n",
      "--------Dataset Done--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloaders, loss_weights = isic_2019(batch_size=BATCH_SIZE, train_shuffle=False)\n",
    "train_dataloader, test_dataloader, test_no_patches = dataloaders[\"train\"], dataloaders[\"test\"], dataloaders[\"test_no_patches\"]\n",
    "model = dnns.VGG16_pretrained_isic().to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss(weight=loss_weights.to(DEVICE))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "n = 0\n",
    "util.seed_all(SEED[n])\n",
    "methods = ['Vanilla', 'RRR', 'RRR-G', 'RBR', 'CDEP', 'HINT', 'CE']\n",
    "IMAGE_INDICES = [i for i in range(9,16)]\n",
    "\n",
    "for j, data_ in enumerate(train_dataloader):\n",
    "    cur_save_name = f'output_images/noXIL_ISIC19-{j}.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data_[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == IMAGE_INDICES[-1]:\n",
    "        break\n",
    "                \n",
    "for i in range(len(methods)):\n",
    "    pretrained_modelname = f'ISIC19-{methods[i]}--seed={SEED[n]}--run={n}'\n",
    "    learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "    explainer.explain_with_ig_one_by_one(learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_ISIC19_{methods[i]}', next_to_each_other=True)\n",
    "    explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_ISIC19_{methods[i]}', next_to_each_other=True)\n",
    "    explainer.explain_with_lime_one_by_one(learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_ISIC19_{methods[i]}', next_to_each_other=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}