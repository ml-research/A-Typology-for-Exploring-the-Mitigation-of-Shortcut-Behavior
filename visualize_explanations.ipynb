{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Explanations\n",
    "\n",
    "This notebook showcases the following expainer methods on pretrained models (DecoyMNIST MLP/CNN. The XIL losses utilize them to generate the models explanation. These model explanations are compared against the user feedback masks. Keep in mind that we currently do not use theses explanatio methods to generate the user feedback masks, as we are using predefined ground-truth masks in evaluation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using cuda device]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from learner.models import dnns\n",
    "from learner.learner import Learner\n",
    "from data_store.datasets import decoy_mnist, decoy_mnist_CE_augmented, isic_2019\n",
    "from xil_methods.xil_loss import RRRGradCamLoss, RRRLoss, CDEPLoss, HINTLoss, RBRLoss\n",
    "import util\n",
    "import explainer\n",
    "\n",
    "LR = 0.001\n",
    "SEED = [1, 10, 100, 1000, 10000]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[Using {DEVICE} device]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN model \n",
    "Define which methods with which regularization rate to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using Seed= 1]\n"
     ]
    }
   ],
   "source": [
    "model = dnns.SimpleConvNet().to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "n = 0  # defines which XIL method to use/ visualize\n",
    "util.seed_all(SEED[n])\n",
    "reg = [None, 10, 10, 1000000, 2000000, 10000 , None]\n",
    "methods = ['Vanilla', 'RRR', 'RRRGradCAM', 'RBR', 'CDEP', 'HINT', 'CE']\n",
    "IMAGE_INDICES = [34] # [i for i in range(20,28)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from existing file!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5270/389611865.py:8: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"cmap\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(cur_save_name ,cmap='gray', bbox_inches='tight')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model DecoyMnist-CNN-RRR--reg=10--seed=1--run=0 loaded! Was trained on RRRLoss() for 0 epochs!\n",
      "explanation image with name IG_MNIST_RRR-34 saved!\n",
      "explanation image with name GRADCAM_MNIST_RRR-34 saved!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbca11b98c140e88801a459fba3f1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation image with name LIME_MNIST_RRR-34 saved!\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = decoy_mnist(device=DEVICE, batch_size=256)\n",
    "for j,data in enumerate(train_loader):\n",
    "    cur_save_name = 'output_images/noXIL_MNIST.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name ,cmap='gray', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == 0:\n",
    "        break\n",
    "               \n",
    "i = 0\n",
    "pretrained_modelname = f'DecoyMnist-CNN-{methods[i]}--reg={reg[i]}--seed={SEED[n]}--run={n}'\n",
    "learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "explainer.explain_with_ig_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_MNIST_{methods[i]}', next_to_each_other=True)\n",
    "explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_MNIST_{methods[i]}', flags=False, next_to_each_other=True)\n",
    "explainer.explain_with_lime_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_MNIST_{methods[i]}', gray_images=True, next_to_each_other=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using Seed= 1]\n",
      "Model DecoyFMnist-CNN-Vanilla--reg=None--seed=1--run=0 loaded! Was trained on CrossEntropyLoss() for 0 epochs!\n",
      "explanation image with name IG_FMNIST_Vanilla-34 saved!\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = decoy_mnist(fmnist=True, device=DEVICE, batch_size=256)\n",
    "for j,data in enumerate(train_loader):\n",
    "    cur_save_name = 'output_images/noXIL_FMNIST.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name ,cmap='gray', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == 0:\n",
    "        break\n",
    "               \n",
    "i = 0\n",
    "pretrained_modelname = f'DecoyFMnist-CNN-{methods[i]}--reg={reg[i]}--seed={SEED[n]}--run={n}'\n",
    "learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "explainer.explain_with_ig_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_FMNIST_{methods[i]}', next_to_each_other=True)\n",
    "explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_FMNIST_{methods[i]}', flags=False, next_to_each_other=True)\n",
    "explainer.explain_with_lime_one_by_one(learner.model, train_loader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_FMNIST_{methods[i]}', gray_images=True, next_to_each_other=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISIC19 Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Dataset----------\n",
      "  Read in data from .h5 files...\n",
      "  --> Read in finished: Took 93 sec!\n",
      "  Building datasets...\n",
      "  Sizes of datasets:\n",
      "  TRAIN: 17829, TEST: 2394, TEST_NO_PATCHES: 2556\n",
      "  TRAIN class dist: Counter({0: 15768, 1: 2061})\n",
      "  TRAIN patch dist: Counter({0: 10521, 1: 7308})\n",
      "  TEST class dist: Counter({0: 1902, 1: 492})\n",
      "  TEST_NO_PATCHES class dist: Counter({0: 2064, 1: 492})\n",
      "  Loss weights: tensor([0.1146, 0.8854])\n",
      "  --> Build finished: Took 3 sec!\n",
      "--------Dataset Done--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloaders, loss_weights = isic_2019(batch_size=BATCH_SIZE, train_shuffle=False)\n",
    "train_dataloader, test_dataloader, test_no_patches = dataloaders[\"train\"], dataloaders[\"test\"], dataloaders[\"test_no_patches\"]\n",
    "model = dnns.VGG16_pretrained_isic().to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss(weight=loss_weights.to(DEVICE))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "n = 0\n",
    "util.seed_all(SEED[n])\n",
    "methods = ['Vanilla', 'RRR', 'RRR-G', 'RBR', 'CDEP', 'HINT', 'CE']\n",
    "IMAGE_INDICES = [i for i in range(9,16)]\n",
    "\n",
    "for j, data_ in enumerate(train_dataloader):\n",
    "    cur_save_name = f'output_images/noXIL_ISIC19-{j}.png'\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.imshow(np.transpose((data_[0][IMAGE_INDICES][0].cpu().detach().numpy()), (1,2,0)))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(cur_save_name, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if j == IMAGE_INDICES[-1]:\n",
    "        break\n",
    "                \n",
    "for i in range(len(methods)):\n",
    "    pretrained_modelname = f'ISIC19-{methods[i]}--seed={SEED[n]}--run={n}'\n",
    "    learner = Learner(model, loss, optimizer, DEVICE, pretrained_modelname, load=True)\n",
    "    explainer.explain_with_ig_one_by_one(learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'IG_ISIC19_{methods[i]}', next_to_each_other=True)\n",
    "    explainer.explain_with_captum_one_by_one('grad_cam', learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'GRADCAM_ISIC19_{methods[i]}', next_to_each_other=True)\n",
    "    explainer.explain_with_lime_one_by_one(learner.model, train_dataloader, specified_img_indices=IMAGE_INDICES, save_name=f'LIME_ISIC19_{methods[i]}', next_to_each_other=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
